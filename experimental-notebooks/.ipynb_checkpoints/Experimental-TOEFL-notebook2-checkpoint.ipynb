{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])\n",
    "    plt.show()\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.corpus.reader import CHILDESCorpusReader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import itertools\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import log as ln\n",
    "\n",
    "import powerlaw\n",
    "\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PromptN(X):\n",
    "    f = open('/Users/Ershui13/Desktop/AES-Project/TOEFL_11/prompts/{}.txt'.format(X),'r')\n",
    "    P = f.read().split('\\n')[2]\n",
    "    return P\n",
    "### All the Prompts start with the same sentence and end with the same sentence too. \n",
    "### The only informative one is the middle one.\n",
    "def Essay(X):\n",
    "    f = open('/Users/Ershui13/Desktop/AES-Project/TOEFL_11/essays/{}'.format(X),'r')\n",
    "    E = f.read()\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = ['P1','P2','P3','P4','P5','P6','P7','P8']\n",
    "data_index = pd.read_csv('/Users/Ershui13/Desktop/AES-Project/TOEFL_11/index.csv')\n",
    "data_index['Prompt_text'] = ''\n",
    "for i in prompts:\n",
    "    data_index.loc[(data_index['Prompt'] == i), 'Prompt_text'] = PromptN(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index['Essay'] = ''\n",
    "for i in data_index['Filename']:\n",
    "    data_index.loc[(data_index['Filename'] == i), 'Essay'] = Essay(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index.to_csv('Essay_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Language</th>\n",
       "      <th>Score Level</th>\n",
       "      <th>Prompt_text</th>\n",
       "      <th>Essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>88.txt</td>\n",
       "      <td>P6</td>\n",
       "      <td>KOR</td>\n",
       "      <td>high</td>\n",
       "      <td>The best way to travel is in a group led by a ...</td>\n",
       "      <td>Some people might think that traveling in a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>278.txt</td>\n",
       "      <td>P6</td>\n",
       "      <td>DEU</td>\n",
       "      <td>medium</td>\n",
       "      <td>The best way to travel is in a group led by a ...</td>\n",
       "      <td>IThe importance and popularity of travelling i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>348.txt</td>\n",
       "      <td>P1</td>\n",
       "      <td>TUR</td>\n",
       "      <td>high</td>\n",
       "      <td>It is better to have broad knowledge of many a...</td>\n",
       "      <td>It is an important decision, how to plan your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>666.txt</td>\n",
       "      <td>P2</td>\n",
       "      <td>ZHO</td>\n",
       "      <td>medium</td>\n",
       "      <td>Young people enjoy life more than older people...</td>\n",
       "      <td>Some people believe that young people can enjo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>733.txt</td>\n",
       "      <td>P6</td>\n",
       "      <td>TEL</td>\n",
       "      <td>medium</td>\n",
       "      <td>The best way to travel is in a group led by a ...</td>\n",
       "      <td>Travelling is  usually considered as good recr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename Prompt Language Score Level  \\\n",
       "0   88.txt     P6      KOR        high   \n",
       "1  278.txt     P6      DEU      medium   \n",
       "2  348.txt     P1      TUR        high   \n",
       "3  666.txt     P2      ZHO      medium   \n",
       "4  733.txt     P6      TEL      medium   \n",
       "\n",
       "                                         Prompt_text  \\\n",
       "0  The best way to travel is in a group led by a ...   \n",
       "1  The best way to travel is in a group led by a ...   \n",
       "2  It is better to have broad knowledge of many a...   \n",
       "3  Young people enjoy life more than older people...   \n",
       "4  The best way to travel is in a group led by a ...   \n",
       "\n",
       "                                               Essay  \n",
       "0  Some people might think that traveling in a gr...  \n",
       "1  IThe importance and popularity of travelling i...  \n",
       "2  It is an important decision, how to plan your ...  \n",
       "3  Some people believe that young people can enjo...  \n",
       "4  Travelling is  usually considered as good recr...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transform each word to the frequency-rank in the essay\n",
    "class Encode:\n",
    "    def __init__ (self, E):\n",
    "        self.E = E\n",
    "    def wordlist (self):\n",
    "        elist = []\n",
    "        for i in self.E.split('\\n'):\n",
    "            worlist = tf.keras.preprocessing.text.text_to_word_sequence(\n",
    "    i, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
    "            elist.append(worlist)\n",
    "            wlist = list(itertools.chain(*elist))\n",
    "        return wlist\n",
    "    def ranklist (self):\n",
    "        elist = []\n",
    "        for i in self.E.split('\\n'):\n",
    "            worlist = tf.keras.preprocessing.text.text_to_word_sequence(\n",
    "    i, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
    "            elist.append(worlist)\n",
    "        wlist = list(itertools.chain(*elist))\n",
    "        Elist = DataFrame(FreqDist(wlist).most_common())\n",
    "        Elist.columns = ['word','count']\n",
    "        Elist['rank'] = list(range(1,len(Elist)+1))\n",
    "        return Elist\n",
    "    def encode (self):\n",
    "        elist = []\n",
    "        for i in self.E.split('\\n'):\n",
    "            worlist = tf.keras.preprocessing.text.text_to_word_sequence(\n",
    "    i, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
    "            elist.append(worlist)\n",
    "        wlist = list(itertools.chain(*elist))\n",
    "        Elist = DataFrame(FreqDist(wlist).most_common())\n",
    "        Elist.columns = ['word','count']\n",
    "        Elist['rank'] = list(range(1,len(Elist)+1))        \n",
    "        numlis = []\n",
    "        for i in wlist:\n",
    "            numlis.append(list(Elist.loc[(Elist['word'] == i), 'rank']))\n",
    "        return list(itertools.chain(*numlis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52aa590039594a68a46cf9d0dabdebeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12100), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocablist = []\n",
    "for i in data_index['Essay']:\n",
    "    vocablist.append(Encode(i).wordlist())\n",
    "for x in tqdm(vocablist):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.array(list(itertools.chain(*vocablist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3831347"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60548"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##vocab size\n",
    "len(np.unique(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encodelist = []\n",
    "for i in data_index['Essay']:\n",
    "    Encodelist.append(Encode(i).encode())\n",
    "data_index['Encoded']=Encodelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Language</th>\n",
       "      <th>Score Level</th>\n",
       "      <th>Prompt_text</th>\n",
       "      <th>Essay</th>\n",
       "      <th>Encoded</th>\n",
       "      <th>Encoded_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>88.txt</td>\n",
       "      <td>P6</td>\n",
       "      <td>KOR</td>\n",
       "      <td>high</td>\n",
       "      <td>The best way to travel is in a group led by a ...</td>\n",
       "      <td>Some people might think that traveling in a gr...</td>\n",
       "      <td>[34, 9, 69, 70, 16, 71, 7, 3, 8, 24, 11, 3, 5,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>278.txt</td>\n",
       "      <td>P6</td>\n",
       "      <td>DEU</td>\n",
       "      <td>medium</td>\n",
       "      <td>The best way to travel is in a group led by a ...</td>\n",
       "      <td>IThe importance and popularity of travelling i...</td>\n",
       "      <td>[50, 51, 9, 52, 35, 53, 6, 54, 55, 56, 6, 57, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>348.txt</td>\n",
       "      <td>P1</td>\n",
       "      <td>TUR</td>\n",
       "      <td>high</td>\n",
       "      <td>It is better to have broad knowledge of many a...</td>\n",
       "      <td>It is an important decision, how to plan your ...</td>\n",
       "      <td>[15, 4, 31, 19, 63, 64, 2, 32, 33, 65, 34, 16,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>666.txt</td>\n",
       "      <td>P2</td>\n",
       "      <td>ZHO</td>\n",
       "      <td>medium</td>\n",
       "      <td>Young people enjoy life more than older people...</td>\n",
       "      <td>Some people believe that young people can enjo...</td>\n",
       "      <td>[69, 2, 42, 43, 3, 2, 31, 13, 10, 32, 21, 6, 7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>733.txt</td>\n",
       "      <td>P6</td>\n",
       "      <td>TEL</td>\n",
       "      <td>medium</td>\n",
       "      <td>The best way to travel is in a group led by a ...</td>\n",
       "      <td>Travelling is  usually considered as good recr...</td>\n",
       "      <td>[9, 12, 35, 53, 36, 54, 55, 16, 37, 13, 36, 37...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename Prompt Language Score Level  \\\n",
       "0   88.txt     P6      KOR        high   \n",
       "1  278.txt     P6      DEU      medium   \n",
       "2  348.txt     P1      TUR        high   \n",
       "3  666.txt     P2      ZHO      medium   \n",
       "4  733.txt     P6      TEL      medium   \n",
       "\n",
       "                                         Prompt_text  \\\n",
       "0  The best way to travel is in a group led by a ...   \n",
       "1  The best way to travel is in a group led by a ...   \n",
       "2  It is better to have broad knowledge of many a...   \n",
       "3  Young people enjoy life more than older people...   \n",
       "4  The best way to travel is in a group led by a ...   \n",
       "\n",
       "                                               Essay  \\\n",
       "0  Some people might think that traveling in a gr...   \n",
       "1  IThe importance and popularity of travelling i...   \n",
       "2  It is an important decision, how to plan your ...   \n",
       "3  Some people believe that young people can enjo...   \n",
       "4  Travelling is  usually considered as good recr...   \n",
       "\n",
       "                                             Encoded Encoded_Level  \n",
       "0  [34, 9, 69, 70, 16, 71, 7, 3, 8, 24, 11, 3, 5,...             2  \n",
       "1  [50, 51, 9, 52, 35, 53, 6, 54, 55, 56, 6, 57, ...             1  \n",
       "2  [15, 4, 31, 19, 63, 64, 2, 32, 33, 65, 34, 16,...             2  \n",
       "3  [69, 2, 42, 43, 3, 2, 31, 13, 10, 32, 21, 6, 7...             1  \n",
       "4  [9, 12, 35, 53, 36, 54, 55, 16, 37, 13, 36, 37...             1  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_index['Encoded_Level'] = ''\n",
    "data_index.loc[(data_index['Score Level'] == 'high'), 'Encoded_Level'] = 2\n",
    "data_index.loc[(data_index['Score Level'] == 'medium'), 'Encoded_Level'] = 1\n",
    "data_index.loc[(data_index['Score Level'] == 'low'), 'Encoded_Level'] = 0\n",
    "data_index.to_csv('Essay_Encoded.csv')\n",
    "data_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9680\n",
      "(9680, 300)\n",
      "2420\n",
      "(2420,)\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all = data_index['Encoded'], data_index['Encoded_Level']\n",
    "train_data, test_data, train_tag, test_tag = train_test_split(X_all, y_all, test_size=0.20, random_state=1)\n",
    "train_padded = pad_sequences(train_data, maxlen=300, padding='post', truncating='post')\n",
    "test_padded = pad_sequences(test_data, maxlen=300, padding='post', truncating='post')\n",
    "X_train = np.asarray(train_padded).astype(np.float32)\n",
    "X_test = np.asarray(test_padded).astype(np.float32)\n",
    "Y_train = np.asarray(train_tag).astype(np.float32)\n",
    "Y_test = np.asarray(test_tag).astype(np.float32)\n",
    "print(len(X_train))\n",
    "print(X_train.shape)\n",
    "print(len(Y_test))\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          320000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 394,694\n",
      "Trainable params: 394,694\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "embedding_dim = 64\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Add an Embedding layer expecting input vocab of size 5000, and output embedding dimension of size 64 we set at the top\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "#    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    # use ReLU in place of tanh function since they are very good alternatives of each other.\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    # Add a Dense layer with 6 units and softmax activation.\n",
    "    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7744 samples, validate on 1936 samples\n",
      "Epoch 1/100\n",
      "7712/7744 [============================>.] - ETA: 0s - loss: 1.4719 - accuracy: 0.5831 - mae: 1.1149 - mse: 1.6698\n",
      "Epoch: 0, accuracy:0.5830,  loss:1.4719,  mae:1.1145,  mse:1.6692,  val_accuracy:0.5961,  val_loss:1.4406,  val_mae:1.0851,  val_mse:1.6297,  \n",
      "7744/7744 [==============================] - 92s 12ms/sample - loss: 1.4719 - accuracy: 0.5830 - mae: 1.1145 - mse: 1.6692 - val_loss: 1.4406 - val_accuracy: 0.5961 - val_mae: 1.0851 - val_mse: 1.6297\n",
      "Epoch 2/100\n",
      "7744/7744 [==============================] - 91s 12ms/sample - loss: 1.4173 - accuracy: 0.6250 - mae: 1.1145 - mse: 1.6930 - val_loss: 1.4329 - val_accuracy: 0.6074 - val_mae: 1.0851 - val_mse: 1.6347\n",
      "Epoch 3/100\n",
      "7744/7744 [==============================] - 86s 11ms/sample - loss: 1.4096 - accuracy: 0.6316 - mae: 1.1145 - mse: 1.6953 - val_loss: 1.4257 - val_accuracy: 0.6142 - val_mae: 1.0851 - val_mse: 1.6329\n",
      "Epoch 4/100\n",
      "7744/7744 [==============================] - 83s 11ms/sample - loss: 1.4116 - accuracy: 0.6273 - mae: 1.1145 - mse: 1.6937 - val_loss: 1.4248 - val_accuracy: 0.6152 - val_mae: 1.0851 - val_mse: 1.6339\n",
      "Epoch 5/100\n",
      "7744/7744 [==============================] - 76s 10ms/sample - loss: 1.4079 - accuracy: 0.6339 - mae: 1.1145 - mse: 1.6954 - val_loss: 1.4255 - val_accuracy: 0.6142 - val_mae: 1.0851 - val_mse: 1.6349\n",
      "Epoch 6/100\n",
      "7744/7744 [==============================] - 80s 10ms/sample - loss: 1.4077 - accuracy: 0.6352 - mae: 1.1145 - mse: 1.6974 - val_loss: 1.4305 - val_accuracy: 0.6095 - val_mae: 1.0851 - val_mse: 1.6364\n",
      "Epoch 7/100\n",
      "7744/7744 [==============================] - 87s 11ms/sample - loss: 1.4075 - accuracy: 0.6346 - mae: 1.1145 - mse: 1.6973 - val_loss: 1.4302 - val_accuracy: 0.6111 - val_mae: 1.0851 - val_mse: 1.6382\n",
      "Epoch 8/100\n",
      "7744/7744 [==============================] - 86s 11ms/sample - loss: 1.4034 - accuracy: 0.6382 - mae: 1.1145 - mse: 1.6974 - val_loss: 1.4236 - val_accuracy: 0.6183 - val_mae: 1.0851 - val_mse: 1.6321\n",
      "Epoch 9/100\n",
      "7744/7744 [==============================] - 87s 11ms/sample - loss: 1.4009 - accuracy: 0.6405 - mae: 1.1145 - mse: 1.6967 - val_loss: 1.4277 - val_accuracy: 0.6142 - val_mae: 1.0851 - val_mse: 1.6377\n",
      "Epoch 10/100\n",
      "7744/7744 [==============================] - 90s 12ms/sample - loss: 1.3989 - accuracy: 0.6445 - mae: 1.1145 - mse: 1.6984 - val_loss: 1.4260 - val_accuracy: 0.6152 - val_mae: 1.0851 - val_mse: 1.6366\n",
      "Epoch 11/100\n",
      "7744/7744 [==============================] - 90s 12ms/sample - loss: 1.3997 - accuracy: 0.6429 - mae: 1.1145 - mse: 1.6994 - val_loss: 1.4351 - val_accuracy: 0.6069 - val_mae: 1.0851 - val_mse: 1.6372\n",
      "Epoch 12/100\n",
      "7744/7744 [==============================] - 84s 11ms/sample - loss: 1.3958 - accuracy: 0.6463 - mae: 1.1145 - mse: 1.6986 - val_loss: 1.4274 - val_accuracy: 0.6157 - val_mae: 1.0851 - val_mse: 1.6386\n",
      "Epoch 13/100\n",
      "7744/7744 [==============================] - 87s 11ms/sample - loss: 1.3978 - accuracy: 0.6449 - mae: 1.1145 - mse: 1.6996 - val_loss: 1.4298 - val_accuracy: 0.6142 - val_mae: 1.0851 - val_mse: 1.6385\n",
      "Epoch 14/100\n",
      "7744/7744 [==============================] - 86s 11ms/sample - loss: 1.3938 - accuracy: 0.6489 - mae: 1.1145 - mse: 1.6992 - val_loss: 1.4309 - val_accuracy: 0.6116 - val_mae: 1.0851 - val_mse: 1.6378\n",
      "Epoch 15/100\n",
      "7744/7744 [==============================] - 87s 11ms/sample - loss: 1.3930 - accuracy: 0.6499 - mae: 1.1145 - mse: 1.6997 - val_loss: 1.4298 - val_accuracy: 0.6126 - val_mae: 1.0851 - val_mse: 1.6379\n",
      "Epoch 16/100\n",
      "7744/7744 [==============================] - 86s 11ms/sample - loss: 1.3945 - accuracy: 0.6473 - mae: 1.1145 - mse: 1.7001 - val_loss: 1.4346 - val_accuracy: 0.6080 - val_mae: 1.0851 - val_mse: 1.6386\n",
      "Epoch 17/100\n",
      "7744/7744 [==============================] - 90s 12ms/sample - loss: 1.3937 - accuracy: 0.6489 - mae: 1.1145 - mse: 1.6995 - val_loss: 1.4271 - val_accuracy: 0.6157 - val_mae: 1.0851 - val_mse: 1.6377\n",
      "Epoch 18/100\n",
      "7744/7744 [==============================] - 88s 11ms/sample - loss: 1.3921 - accuracy: 0.6510 - mae: 1.1145 - mse: 1.6995 - val_loss: 1.4282 - val_accuracy: 0.6152 - val_mae: 1.0851 - val_mse: 1.6390\n",
      "Epoch 19/100\n",
      "7744/7744 [==============================] - 92s 12ms/sample - loss: 1.4014 - accuracy: 0.6422 - mae: 1.1145 - mse: 1.6999 - val_loss: 1.4300 - val_accuracy: 0.6131 - val_mae: 1.0851 - val_mse: 1.6379\n",
      "Epoch 20/100\n",
      "7744/7744 [==============================] - 92s 12ms/sample - loss: 1.3950 - accuracy: 0.6484 - mae: 1.1145 - mse: 1.6993 - val_loss: 1.4379 - val_accuracy: 0.6033 - val_mae: 1.0851 - val_mse: 1.6373\n",
      "Epoch 21/100\n",
      "7744/7744 [==============================] - 88s 11ms/sample - loss: 1.3883 - accuracy: 0.6552 - mae: 1.1145 - mse: 1.6991 - val_loss: 1.4270 - val_accuracy: 0.6167 - val_mae: 1.0851 - val_mse: 1.6389\n",
      "Epoch 22/100\n",
      "7744/7744 [==============================] - 83s 11ms/sample - loss: 1.3932 - accuracy: 0.6482 - mae: 1.1145 - mse: 1.6989 - val_loss: 1.4298 - val_accuracy: 0.6131 - val_mae: 1.0851 - val_mse: 1.6385\n",
      "Epoch 23/100\n",
      "7744/7744 [==============================] - 86s 11ms/sample - loss: 1.3878 - accuracy: 0.6550 - mae: 1.1145 - mse: 1.6995 - val_loss: 1.4278 - val_accuracy: 0.6142 - val_mae: 1.0851 - val_mse: 1.6379\n",
      "Epoch 24/100\n",
      "7744/7744 [==============================] - 94s 12ms/sample - loss: 1.3840 - accuracy: 0.6588 - mae: 1.1145 - mse: 1.6996 - val_loss: 1.4277 - val_accuracy: 0.6152 - val_mae: 1.0851 - val_mse: 1.6388\n",
      "Epoch 25/100\n",
      "7744/7744 [==============================] - 88s 11ms/sample - loss: 1.3839 - accuracy: 0.6590 - mae: 1.1145 - mse: 1.6997 - val_loss: 1.4332 - val_accuracy: 0.6064 - val_mae: 1.0851 - val_mse: 1.6388\n",
      "Epoch 26/100\n",
      "7744/7744 [==============================] - 90s 12ms/sample - loss: 1.3854 - accuracy: 0.6584 - mae: 1.1145 - mse: 1.7000 - val_loss: 1.4270 - val_accuracy: 0.6152 - val_mae: 1.0851 - val_mse: 1.6393\n",
      "Epoch 27/100\n",
      "7744/7744 [==============================] - 98s 13ms/sample - loss: 1.3820 - accuracy: 0.6610 - mae: 1.1145 - mse: 1.7000 - val_loss: 1.4319 - val_accuracy: 0.6121 - val_mae: 1.0851 - val_mse: 1.6373\n",
      "Epoch 28/100\n",
      "7744/7744 [==============================] - 143s 18ms/sample - loss: 1.3822 - accuracy: 0.6610 - mae: 1.1145 - mse: 1.7000 - val_loss: 1.4295 - val_accuracy: 0.6136 - val_mae: 1.0851 - val_mse: 1.6388\n",
      "Epoch 29/100\n",
      "7744/7744 [==============================] - 112s 14ms/sample - loss: 1.3802 - accuracy: 0.6631 - mae: 1.1145 - mse: 1.7001 - val_loss: 1.4289 - val_accuracy: 0.6136 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 30/100\n",
      "7744/7744 [==============================] - 102s 13ms/sample - loss: 1.3813 - accuracy: 0.6613 - mae: 1.1145 - mse: 1.7001 - val_loss: 1.4365 - val_accuracy: 0.6059 - val_mae: 1.0851 - val_mse: 1.6386\n",
      "Epoch 31/100\n",
      "7744/7744 [==============================] - 92s 12ms/sample - loss: 1.3772 - accuracy: 0.6663 - mae: 1.1145 - mse: 1.6999 - val_loss: 1.4346 - val_accuracy: 0.6069 - val_mae: 1.0851 - val_mse: 1.6391\n",
      "Epoch 32/100\n",
      "7744/7744 [==============================] - 102s 13ms/sample - loss: 1.3760 - accuracy: 0.6681 - mae: 1.1145 - mse: 1.7004 - val_loss: 1.4382 - val_accuracy: 0.6043 - val_mae: 1.0851 - val_mse: 1.6391\n",
      "Epoch 33/100\n",
      "7744/7744 [==============================] - 100s 13ms/sample - loss: 1.3761 - accuracy: 0.6665 - mae: 1.1145 - mse: 1.7004 - val_loss: 1.4365 - val_accuracy: 0.6038 - val_mae: 1.0851 - val_mse: 1.6386\n",
      "Epoch 34/100\n",
      "7744/7744 [==============================] - 93s 12ms/sample - loss: 1.3786 - accuracy: 0.6650 - mae: 1.1145 - mse: 1.7004 - val_loss: 1.4405 - val_accuracy: 0.6012 - val_mae: 1.0851 - val_mse: 1.6391\n",
      "Epoch 35/100\n",
      "7744/7744 [==============================] - 103s 13ms/sample - loss: 1.3775 - accuracy: 0.6653 - mae: 1.1145 - mse: 1.7003 - val_loss: 1.4338 - val_accuracy: 0.6080 - val_mae: 1.0851 - val_mse: 1.6396\n",
      "Epoch 36/100\n",
      "7744/7744 [==============================] - 85s 11ms/sample - loss: 1.3958 - accuracy: 0.6476 - mae: 1.1145 - mse: 1.7003 - val_loss: 1.4324 - val_accuracy: 0.6116 - val_mae: 1.0851 - val_mse: 1.6390\n",
      "Epoch 37/100\n",
      "7744/7744 [==============================] - 99s 13ms/sample - loss: 1.4118 - accuracy: 0.6308 - mae: 1.1145 - mse: 1.6995 - val_loss: 1.4369 - val_accuracy: 0.6043 - val_mae: 1.0851 - val_mse: 1.6392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "7744/7744 [==============================] - 97s 13ms/sample - loss: 1.3918 - accuracy: 0.6507 - mae: 1.1145 - mse: 1.7003 - val_loss: 1.4350 - val_accuracy: 0.6074 - val_mae: 1.0851 - val_mse: 1.6384\n",
      "Epoch 39/100\n",
      "7744/7744 [==============================] - 111s 14ms/sample - loss: 1.3796 - accuracy: 0.6635 - mae: 1.1145 - mse: 1.7003 - val_loss: 1.4318 - val_accuracy: 0.6095 - val_mae: 1.0851 - val_mse: 1.6387\n",
      "Epoch 40/100\n",
      "7744/7744 [==============================] - 92s 12ms/sample - loss: 1.3764 - accuracy: 0.6661 - mae: 1.1145 - mse: 1.7006 - val_loss: 1.4348 - val_accuracy: 0.6085 - val_mae: 1.0851 - val_mse: 1.6395\n",
      "Epoch 41/100\n",
      "7744/7744 [==============================] - 87s 11ms/sample - loss: 1.3836 - accuracy: 0.6590 - mae: 1.1145 - mse: 1.7005 - val_loss: 1.4356 - val_accuracy: 0.6074 - val_mae: 1.0851 - val_mse: 1.6391\n",
      "Epoch 42/100\n",
      "7744/7744 [==============================] - 83s 11ms/sample - loss: 1.3753 - accuracy: 0.6684 - mae: 1.1145 - mse: 1.7007 - val_loss: 1.4327 - val_accuracy: 0.6100 - val_mae: 1.0851 - val_mse: 1.6395\n",
      "Epoch 43/100\n",
      "7744/7744 [==============================] - 99s 13ms/sample - loss: 1.3710 - accuracy: 0.6726 - mae: 1.1145 - mse: 1.7008 - val_loss: 1.4383 - val_accuracy: 0.6049 - val_mae: 1.0851 - val_mse: 1.6393\n",
      "Epoch 44/100\n",
      "7744/7744 [==============================] - 72s 9ms/sample - loss: 1.3672 - accuracy: 0.6765 - mae: 1.1145 - mse: 1.7010 - val_loss: 1.4371 - val_accuracy: 0.6049 - val_mae: 1.0851 - val_mse: 1.6395\n",
      "Epoch 45/100\n",
      "7744/7744 [==============================] - 73s 9ms/sample - loss: 1.3646 - accuracy: 0.6792 - mae: 1.1145 - mse: 1.7011 - val_loss: 1.4343 - val_accuracy: 0.6069 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 46/100\n",
      "7744/7744 [==============================] - 70s 9ms/sample - loss: 1.3672 - accuracy: 0.6755 - mae: 1.1145 - mse: 1.7010 - val_loss: 1.4352 - val_accuracy: 0.6059 - val_mae: 1.0851 - val_mse: 1.6395\n",
      "Epoch 47/100\n",
      "7744/7744 [==============================] - 78s 10ms/sample - loss: 1.3625 - accuracy: 0.6810 - mae: 1.1145 - mse: 1.7012 - val_loss: 1.4339 - val_accuracy: 0.6095 - val_mae: 1.0851 - val_mse: 1.6395\n",
      "Epoch 48/100\n",
      "7744/7744 [==============================] - 81s 10ms/sample - loss: 1.3634 - accuracy: 0.6799 - mae: 1.1145 - mse: 1.7011 - val_loss: 1.4360 - val_accuracy: 0.6074 - val_mae: 1.0851 - val_mse: 1.6396\n",
      "Epoch 49/100\n",
      "7744/7744 [==============================] - 74s 10ms/sample - loss: 1.3620 - accuracy: 0.6809 - mae: 1.1145 - mse: 1.7011 - val_loss: 1.4387 - val_accuracy: 0.6033 - val_mae: 1.0851 - val_mse: 1.6395\n",
      "Epoch 50/100\n",
      "7744/7744 [==============================] - 85s 11ms/sample - loss: 1.3665 - accuracy: 0.6772 - mae: 1.1145 - mse: 1.7010 - val_loss: 1.4353 - val_accuracy: 0.6069 - val_mae: 1.0851 - val_mse: 1.6396\n",
      "Epoch 51/100\n",
      "7744/7744 [==============================] - 73s 9ms/sample - loss: 1.3605 - accuracy: 0.6827 - mae: 1.1145 - mse: 1.7012 - val_loss: 1.4323 - val_accuracy: 0.6095 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 52/100\n",
      "7744/7744 [==============================] - 85s 11ms/sample - loss: 1.3585 - accuracy: 0.6858 - mae: 1.1145 - mse: 1.7011 - val_loss: 1.4299 - val_accuracy: 0.6131 - val_mae: 1.0851 - val_mse: 1.6400\n",
      "Epoch 53/100\n",
      "7744/7744 [==============================] - 86s 11ms/sample - loss: 1.3567 - accuracy: 0.6872 - mae: 1.1145 - mse: 1.7013 - val_loss: 1.4331 - val_accuracy: 0.6085 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 54/100\n",
      "7744/7744 [==============================] - 84s 11ms/sample - loss: 1.3558 - accuracy: 0.6878 - mae: 1.1145 - mse: 1.7014 - val_loss: 1.4339 - val_accuracy: 0.6090 - val_mae: 1.0851 - val_mse: 1.6399\n",
      "Epoch 55/100\n",
      "7744/7744 [==============================] - 84s 11ms/sample - loss: 1.3553 - accuracy: 0.6884 - mae: 1.1145 - mse: 1.7011 - val_loss: 1.4335 - val_accuracy: 0.6080 - val_mae: 1.0851 - val_mse: 1.6396\n",
      "Epoch 56/100\n",
      "7744/7744 [==============================] - 89s 12ms/sample - loss: 1.3592 - accuracy: 0.6836 - mae: 1.1145 - mse: 1.7011 - val_loss: 1.4339 - val_accuracy: 0.6085 - val_mae: 1.0851 - val_mse: 1.6390\n",
      "Epoch 57/100\n",
      "7744/7744 [==============================] - 82s 11ms/sample - loss: 1.3628 - accuracy: 0.6805 - mae: 1.1145 - mse: 1.7009 - val_loss: 1.4290 - val_accuracy: 0.6152 - val_mae: 1.0851 - val_mse: 1.6396\n",
      "Epoch 58/100\n",
      "7744/7744 [==============================] - 98s 13ms/sample - loss: 1.3560 - accuracy: 0.6874 - mae: 1.1145 - mse: 1.7013 - val_loss: 1.4347 - val_accuracy: 0.6074 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 59/100\n",
      "7744/7744 [==============================] - 72s 9ms/sample - loss: 1.3584 - accuracy: 0.6848 - mae: 1.1145 - mse: 1.7011 - val_loss: 1.4363 - val_accuracy: 0.6059 - val_mae: 1.0851 - val_mse: 1.6397\n",
      "Epoch 60/100\n",
      "7744/7744 [==============================] - 74s 10ms/sample - loss: 1.3578 - accuracy: 0.6860 - mae: 1.1145 - mse: 1.7011 - val_loss: 1.4313 - val_accuracy: 0.6116 - val_mae: 1.0851 - val_mse: 1.6400\n",
      "Epoch 61/100\n",
      "7744/7744 [==============================] - 74s 10ms/sample - loss: 1.3516 - accuracy: 0.6918 - mae: 1.1145 - mse: 1.7013 - val_loss: 1.4309 - val_accuracy: 0.6126 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 62/100\n",
      "7744/7744 [==============================] - 70s 9ms/sample - loss: 1.3481 - accuracy: 0.6950 - mae: 1.1145 - mse: 1.7016 - val_loss: 1.4300 - val_accuracy: 0.6100 - val_mae: 1.0851 - val_mse: 1.6399\n",
      "Epoch 63/100\n",
      "7744/7744 [==============================] - 70s 9ms/sample - loss: 1.3478 - accuracy: 0.6959 - mae: 1.1145 - mse: 1.7014 - val_loss: 1.4328 - val_accuracy: 0.6105 - val_mae: 1.0851 - val_mse: 1.6397\n",
      "Epoch 64/100\n",
      "7744/7744 [==============================] - 70s 9ms/sample - loss: 1.3436 - accuracy: 0.6999 - mae: 1.1145 - mse: 1.7016 - val_loss: 1.4310 - val_accuracy: 0.6116 - val_mae: 1.0851 - val_mse: 1.6401\n",
      "Epoch 65/100\n",
      "7744/7744 [==============================] - 70s 9ms/sample - loss: 1.3444 - accuracy: 0.7000 - mae: 1.1145 - mse: 1.7015 - val_loss: 1.4345 - val_accuracy: 0.6085 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 66/100\n",
      "7744/7744 [==============================] - 70s 9ms/sample - loss: 1.3446 - accuracy: 0.6991 - mae: 1.1145 - mse: 1.7017 - val_loss: 1.4380 - val_accuracy: 0.6064 - val_mae: 1.0851 - val_mse: 1.6400\n",
      "Epoch 67/100\n",
      "7744/7744 [==============================] - 72s 9ms/sample - loss: 1.3399 - accuracy: 0.7038 - mae: 1.1145 - mse: 1.7017 - val_loss: 1.4353 - val_accuracy: 0.6085 - val_mae: 1.0851 - val_mse: 1.6400\n",
      "Epoch 68/100\n",
      "7744/7744 [==============================] - 73s 9ms/sample - loss: 1.3452 - accuracy: 0.6978 - mae: 1.1145 - mse: 1.7015 - val_loss: 1.4387 - val_accuracy: 0.6038 - val_mae: 1.0851 - val_mse: 1.6396\n",
      "Epoch 69/100\n",
      "7744/7744 [==============================] - 83s 11ms/sample - loss: 1.3364 - accuracy: 0.7075 - mae: 1.1145 - mse: 1.7019 - val_loss: 1.4379 - val_accuracy: 0.6049 - val_mae: 1.0851 - val_mse: 1.6396\n",
      "Epoch 70/100\n",
      "7744/7744 [==============================] - 78s 10ms/sample - loss: 1.3366 - accuracy: 0.7074 - mae: 1.1145 - mse: 1.7018 - val_loss: 1.4347 - val_accuracy: 0.6080 - val_mae: 1.0851 - val_mse: 1.6399\n",
      "Epoch 71/100\n",
      "7744/7744 [==============================] - 73s 9ms/sample - loss: 1.3378 - accuracy: 0.7058 - mae: 1.1145 - mse: 1.7018 - val_loss: 1.4330 - val_accuracy: 0.6095 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 72/100\n",
      "7744/7744 [==============================] - 70s 9ms/sample - loss: 1.3461 - accuracy: 0.6972 - mae: 1.1145 - mse: 1.7016 - val_loss: 1.4314 - val_accuracy: 0.6121 - val_mae: 1.0851 - val_mse: 1.6399\n",
      "Epoch 73/100\n",
      "7744/7744 [==============================] - 77s 10ms/sample - loss: 1.3393 - accuracy: 0.7045 - mae: 1.1145 - mse: 1.7016 - val_loss: 1.4320 - val_accuracy: 0.6111 - val_mae: 1.0851 - val_mse: 1.6402\n",
      "Epoch 74/100\n",
      "7744/7744 [==============================] - 86s 11ms/sample - loss: 1.3375 - accuracy: 0.7061 - mae: 1.1145 - mse: 1.7016 - val_loss: 1.4323 - val_accuracy: 0.6095 - val_mae: 1.0851 - val_mse: 1.6395\n",
      "Epoch 75/100\n",
      "7744/7744 [==============================] - 73s 9ms/sample - loss: 1.3329 - accuracy: 0.7111 - mae: 1.1145 - mse: 1.7019 - val_loss: 1.4357 - val_accuracy: 0.6074 - val_mae: 1.0851 - val_mse: 1.6399\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7744/7744 [==============================] - 85s 11ms/sample - loss: 1.3386 - accuracy: 0.7052 - mae: 1.1145 - mse: 1.7016 - val_loss: 1.4365 - val_accuracy: 0.6064 - val_mae: 1.0851 - val_mse: 1.6401\n",
      "Epoch 77/100\n",
      "7744/7744 [==============================] - 97s 12ms/sample - loss: 1.3348 - accuracy: 0.7089 - mae: 1.1145 - mse: 1.7019 - val_loss: 1.4363 - val_accuracy: 0.6069 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 78/100\n",
      "7744/7744 [==============================] - 90s 12ms/sample - loss: 1.3333 - accuracy: 0.7104 - mae: 1.1145 - mse: 1.7018 - val_loss: 1.4398 - val_accuracy: 0.6028 - val_mae: 1.0851 - val_mse: 1.6400\n",
      "Epoch 79/100\n",
      "7744/7744 [==============================] - 77s 10ms/sample - loss: 1.3318 - accuracy: 0.7118 - mae: 1.1145 - mse: 1.7018 - val_loss: 1.4365 - val_accuracy: 0.6064 - val_mae: 1.0851 - val_mse: 1.6400\n",
      "Epoch 80/100\n",
      "7744/7744 [==============================] - 74s 10ms/sample - loss: 1.3321 - accuracy: 0.7111 - mae: 1.1145 - mse: 1.7019 - val_loss: 1.4317 - val_accuracy: 0.6126 - val_mae: 1.0851 - val_mse: 1.6400\n",
      "Epoch 81/100\n",
      "7744/7744 [==============================] - 77s 10ms/sample - loss: 1.3318 - accuracy: 0.7119 - mae: 1.1145 - mse: 1.7019 - val_loss: 1.4307 - val_accuracy: 0.6111 - val_mae: 1.0851 - val_mse: 1.6399\n",
      "Epoch 82/100\n",
      "7744/7744 [==============================] - 98s 13ms/sample - loss: 1.3378 - accuracy: 0.7058 - mae: 1.1145 - mse: 1.7015 - val_loss: 1.4389 - val_accuracy: 0.6038 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 83/100\n",
      "7744/7744 [==============================] - 98s 13ms/sample - loss: 1.3578 - accuracy: 0.6856 - mae: 1.1145 - mse: 1.7013 - val_loss: 1.4367 - val_accuracy: 0.6059 - val_mae: 1.0851 - val_mse: 1.6397\n",
      "Epoch 84/100\n",
      "7744/7744 [==============================] - 79s 10ms/sample - loss: 1.3424 - accuracy: 0.7007 - mae: 1.1145 - mse: 1.7016 - val_loss: 1.4367 - val_accuracy: 0.6054 - val_mae: 1.0851 - val_mse: 1.6396\n",
      "Epoch 85/100\n",
      "7744/7744 [==============================] - 70s 9ms/sample - loss: 1.3343 - accuracy: 0.7095 - mae: 1.1145 - mse: 1.7017 - val_loss: 1.4353 - val_accuracy: 0.6080 - val_mae: 1.0851 - val_mse: 1.6397\n",
      "Epoch 86/100\n",
      "7744/7744 [==============================] - 69s 9ms/sample - loss: 1.3317 - accuracy: 0.7120 - mae: 1.1145 - mse: 1.7020 - val_loss: 1.4383 - val_accuracy: 0.6054 - val_mae: 1.0851 - val_mse: 1.6399\n",
      "Epoch 87/100\n",
      "7744/7744 [==============================] - 83s 11ms/sample - loss: 1.3338 - accuracy: 0.7093 - mae: 1.1145 - mse: 1.7017 - val_loss: 1.4382 - val_accuracy: 0.6038 - val_mae: 1.0851 - val_mse: 1.6400\n",
      "Epoch 88/100\n",
      "7744/7744 [==============================] - 81s 11ms/sample - loss: 1.3340 - accuracy: 0.7102 - mae: 1.1145 - mse: 1.7017 - val_loss: 1.4403 - val_accuracy: 0.6018 - val_mae: 1.0851 - val_mse: 1.6399\n",
      "Epoch 89/100\n",
      "7744/7744 [==============================] - 80s 10ms/sample - loss: 1.3302 - accuracy: 0.7137 - mae: 1.1145 - mse: 1.7018 - val_loss: 1.4393 - val_accuracy: 0.6023 - val_mae: 1.0851 - val_mse: 1.6399\n",
      "Epoch 90/100\n",
      "7744/7744 [==============================] - 77s 10ms/sample - loss: 1.3290 - accuracy: 0.7151 - mae: 1.1145 - mse: 1.7018 - val_loss: 1.4374 - val_accuracy: 0.6038 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 91/100\n",
      "7744/7744 [==============================] - 85s 11ms/sample - loss: 1.3278 - accuracy: 0.7162 - mae: 1.1145 - mse: 1.7018 - val_loss: 1.4370 - val_accuracy: 0.6054 - val_mae: 1.0851 - val_mse: 1.6396\n",
      "Epoch 92/100\n",
      "7744/7744 [==============================] - 79s 10ms/sample - loss: 1.3242 - accuracy: 0.7195 - mae: 1.1145 - mse: 1.7020 - val_loss: 1.4392 - val_accuracy: 0.6023 - val_mae: 1.0851 - val_mse: 1.6401\n",
      "Epoch 93/100\n",
      "7744/7744 [==============================] - 91s 12ms/sample - loss: 1.3223 - accuracy: 0.7213 - mae: 1.1145 - mse: 1.7021 - val_loss: 1.4391 - val_accuracy: 0.6038 - val_mae: 1.0851 - val_mse: 1.6400\n",
      "Epoch 94/100\n",
      "7744/7744 [==============================] - 86s 11ms/sample - loss: 1.3201 - accuracy: 0.7233 - mae: 1.1145 - mse: 1.7021 - val_loss: 1.4478 - val_accuracy: 0.5940 - val_mae: 1.0851 - val_mse: 1.6399\n",
      "Epoch 95/100\n",
      "7744/7744 [==============================] - 82s 11ms/sample - loss: 1.3213 - accuracy: 0.7225 - mae: 1.1145 - mse: 1.7021 - val_loss: 1.4373 - val_accuracy: 0.6043 - val_mae: 1.0851 - val_mse: 1.6396\n",
      "Epoch 96/100\n",
      "7744/7744 [==============================] - 81s 10ms/sample - loss: 1.3213 - accuracy: 0.7222 - mae: 1.1145 - mse: 1.7019 - val_loss: 1.4366 - val_accuracy: 0.6049 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 97/100\n",
      "7744/7744 [==============================] - 83s 11ms/sample - loss: 1.3199 - accuracy: 0.7238 - mae: 1.1145 - mse: 1.7019 - val_loss: 1.4383 - val_accuracy: 0.6054 - val_mae: 1.0851 - val_mse: 1.6401\n",
      "Epoch 98/100\n",
      "7744/7744 [==============================] - 85s 11ms/sample - loss: 1.3220 - accuracy: 0.7218 - mae: 1.1145 - mse: 1.7018 - val_loss: 1.4398 - val_accuracy: 0.6038 - val_mae: 1.0851 - val_mse: 1.6398\n",
      "Epoch 99/100\n",
      "7744/7744 [==============================] - 78s 10ms/sample - loss: 1.3254 - accuracy: 0.7184 - mae: 1.1145 - mse: 1.7017 - val_loss: 1.4436 - val_accuracy: 0.5997 - val_mae: 1.0851 - val_mse: 1.6400\n",
      "Epoch 100/100\n",
      "7744/7744 [==============================] - 88s 11ms/sample - loss: 1.3361 - accuracy: 0.7067 - mae: 1.1145 - mse: 1.7016 - val_loss: 1.4479 - val_accuracy: 0.5961 - val_mae: 1.0851 - val_mse: 1.6394\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy','mae', 'mse'])\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n",
    "\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    validation_split = 0.2, \n",
    "                    callbacks=[early_stop, tfdocs.modeling.EpochDots()], \n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
    "\n",
    "plotter.plot({'Accuracy': history}, metric = \"accuracy\")\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2420/2420 - 5s - loss: 1.4531 - accuracy: 0.5909 - mae: 1.1022 - mse: 1.6680\n",
      "Test set loss:  1.45 , accuracy:  0.59, mae:  1.10, mse:  1.67  \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy ,mae, mse = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print(\"Test set loss: {:5.2f} , accuracy: {:5.2f}, mae: {:5.2f}, mse: {:5.2f}  \".format(loss, accuracy, mae, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low      0.000     0.000     0.000       260\n",
      "      medium      0.606     0.749     0.670      1336\n",
      "        high      0.558     0.521     0.539       824\n",
      "\n",
      "    accuracy                          0.591      2420\n",
      "   macro avg      0.388     0.423     0.403      2420\n",
      "weighted avg      0.525     0.591     0.553      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "target_names = ['low', 'medium', 'high']\n",
    "print(metrics.classification_report(Y_test, y_pred, digits=3, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWK 0.32756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "print('QWK {:5.5f}'.format(cohen_kappa_score(Y_test, y_pred, weights='quadratic')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
