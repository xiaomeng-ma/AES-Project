{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "simple-deep-learning-on-toefl-dataset.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SftuBzlcD_kd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qds7KXYCEJVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e5637dc-bf59-42a8-c519-7af60c4d59d7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDDRfLyUERJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDxMBv1IFrTO",
        "colab_type": "text"
      },
      "source": [
        "**Get the data**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Read toefl data from project repositoy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mRUaMcxErGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "07228204-be3c-47c5-9124-3518392a90e0"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/xiaomeng-ma/AES-Project/master/TOEFL_11/processed_toefl.csv?token=AKHHIKHHXT4NNHAUAQFLBDS6V4QSI')\n",
        "df.head()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Language</th>\n",
              "      <th>Score Level</th>\n",
              "      <th>total word</th>\n",
              "      <th>distance</th>\n",
              "      <th>Hpoint</th>\n",
              "      <th>xmin</th>\n",
              "      <th>alpha</th>\n",
              "      <th>mu</th>\n",
              "      <th>sigma</th>\n",
              "      <th>logtrue</th>\n",
              "      <th>file</th>\n",
              "      <th>pl_s</th>\n",
              "      <th>pl_C</th>\n",
              "      <th>pl_R2</th>\n",
              "      <th>log_d</th>\n",
              "      <th>log_m</th>\n",
              "      <th>log_k</th>\n",
              "      <th>log_R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>385</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.273182</td>\n",
              "      <td>-10.388887</td>\n",
              "      <td>3.025490</td>\n",
              "      <td>0</td>\n",
              "      <td>88</td>\n",
              "      <td>0.626725</td>\n",
              "      <td>27.346485</td>\n",
              "      <td>0.883300</td>\n",
              "      <td>3.478245</td>\n",
              "      <td>0.639538</td>\n",
              "      <td>1.090635</td>\n",
              "      <td>0.869275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>medium</td>\n",
              "      <td>321</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.421178</td>\n",
              "      <td>-2.618379</td>\n",
              "      <td>1.817156</td>\n",
              "      <td>0</td>\n",
              "      <td>278</td>\n",
              "      <td>0.720874</td>\n",
              "      <td>31.641664</td>\n",
              "      <td>0.962596</td>\n",
              "      <td>3.573915</td>\n",
              "      <td>0.757765</td>\n",
              "      <td>1.032666</td>\n",
              "      <td>0.951214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>high</td>\n",
              "      <td>363</td>\n",
              "      <td>8.306624</td>\n",
              "      <td>6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.398038</td>\n",
              "      <td>-2.825649</td>\n",
              "      <td>1.739209</td>\n",
              "      <td>0</td>\n",
              "      <td>348</td>\n",
              "      <td>0.621470</td>\n",
              "      <td>21.737883</td>\n",
              "      <td>0.965709</td>\n",
              "      <td>3.352892</td>\n",
              "      <td>0.874682</td>\n",
              "      <td>0.849857</td>\n",
              "      <td>0.889519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>medium</td>\n",
              "      <td>362</td>\n",
              "      <td>4.690416</td>\n",
              "      <td>6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.410995</td>\n",
              "      <td>0.835672</td>\n",
              "      <td>0.746383</td>\n",
              "      <td>0</td>\n",
              "      <td>666</td>\n",
              "      <td>0.538645</td>\n",
              "      <td>18.320499</td>\n",
              "      <td>0.924139</td>\n",
              "      <td>2.824981</td>\n",
              "      <td>0.296708</td>\n",
              "      <td>1.441791</td>\n",
              "      <td>0.969115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>medium</td>\n",
              "      <td>344</td>\n",
              "      <td>10.630146</td>\n",
              "      <td>7</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.124099</td>\n",
              "      <td>-0.359383</td>\n",
              "      <td>1.163868</td>\n",
              "      <td>0</td>\n",
              "      <td>733</td>\n",
              "      <td>0.646729</td>\n",
              "      <td>25.998149</td>\n",
              "      <td>0.938335</td>\n",
              "      <td>3.393319</td>\n",
              "      <td>0.638436</td>\n",
              "      <td>1.093227</td>\n",
              "      <td>0.926643</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Prompt  Language Score Level  ...     log_m     log_k    log_R2\n",
              "0       5         6        high  ...  0.639538  1.090635  0.869275\n",
              "1       5         1      medium  ...  0.757765  1.032666  0.951214\n",
              "2       0         9        high  ...  0.874682  0.849857  0.889519\n",
              "3       1        10      medium  ...  0.296708  1.441791  0.969115\n",
              "4       5         8      medium  ...  0.638436  1.093227  0.926643\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdxaXajlHQtS",
        "colab_type": "text"
      },
      "source": [
        "**Convert Target column to numberic**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg9amSPhZ_XH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dcde516e-28a6-4cd1-ad10-d833d093e9b6"
      },
      "source": [
        "score_mapping ={\n",
        "    'low':0,\n",
        "    'medium':1,\n",
        "    'high': 2\n",
        "}\n",
        "inv_score_mapping = {v: k for k, v in score_mapping.items()}\n",
        "df['Score Level'] = df['Score Level'].map(score_mapping)\n",
        "df.head()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Language</th>\n",
              "      <th>Score Level</th>\n",
              "      <th>total word</th>\n",
              "      <th>distance</th>\n",
              "      <th>Hpoint</th>\n",
              "      <th>xmin</th>\n",
              "      <th>alpha</th>\n",
              "      <th>mu</th>\n",
              "      <th>sigma</th>\n",
              "      <th>logtrue</th>\n",
              "      <th>file</th>\n",
              "      <th>pl_s</th>\n",
              "      <th>pl_C</th>\n",
              "      <th>pl_R2</th>\n",
              "      <th>log_d</th>\n",
              "      <th>log_m</th>\n",
              "      <th>log_k</th>\n",
              "      <th>log_R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>385</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.273182</td>\n",
              "      <td>-10.388887</td>\n",
              "      <td>3.025490</td>\n",
              "      <td>0</td>\n",
              "      <td>88</td>\n",
              "      <td>0.626725</td>\n",
              "      <td>27.346485</td>\n",
              "      <td>0.883300</td>\n",
              "      <td>3.478245</td>\n",
              "      <td>0.639538</td>\n",
              "      <td>1.090635</td>\n",
              "      <td>0.869275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>321</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.421178</td>\n",
              "      <td>-2.618379</td>\n",
              "      <td>1.817156</td>\n",
              "      <td>0</td>\n",
              "      <td>278</td>\n",
              "      <td>0.720874</td>\n",
              "      <td>31.641664</td>\n",
              "      <td>0.962596</td>\n",
              "      <td>3.573915</td>\n",
              "      <td>0.757765</td>\n",
              "      <td>1.032666</td>\n",
              "      <td>0.951214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>363</td>\n",
              "      <td>8.306624</td>\n",
              "      <td>6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.398038</td>\n",
              "      <td>-2.825649</td>\n",
              "      <td>1.739209</td>\n",
              "      <td>0</td>\n",
              "      <td>348</td>\n",
              "      <td>0.621470</td>\n",
              "      <td>21.737883</td>\n",
              "      <td>0.965709</td>\n",
              "      <td>3.352892</td>\n",
              "      <td>0.874682</td>\n",
              "      <td>0.849857</td>\n",
              "      <td>0.889519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>362</td>\n",
              "      <td>4.690416</td>\n",
              "      <td>6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.410995</td>\n",
              "      <td>0.835672</td>\n",
              "      <td>0.746383</td>\n",
              "      <td>0</td>\n",
              "      <td>666</td>\n",
              "      <td>0.538645</td>\n",
              "      <td>18.320499</td>\n",
              "      <td>0.924139</td>\n",
              "      <td>2.824981</td>\n",
              "      <td>0.296708</td>\n",
              "      <td>1.441791</td>\n",
              "      <td>0.969115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>344</td>\n",
              "      <td>10.630146</td>\n",
              "      <td>7</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.124099</td>\n",
              "      <td>-0.359383</td>\n",
              "      <td>1.163868</td>\n",
              "      <td>0</td>\n",
              "      <td>733</td>\n",
              "      <td>0.646729</td>\n",
              "      <td>25.998149</td>\n",
              "      <td>0.938335</td>\n",
              "      <td>3.393319</td>\n",
              "      <td>0.638436</td>\n",
              "      <td>1.093227</td>\n",
              "      <td>0.926643</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Prompt  Language  Score Level  ...     log_m     log_k    log_R2\n",
              "0       5         6            2  ...  0.639538  1.090635  0.869275\n",
              "1       5         1            1  ...  0.757765  1.032666  0.951214\n",
              "2       0         9            2  ...  0.874682  0.849857  0.889519\n",
              "3       1        10            1  ...  0.296708  1.441791  0.969115\n",
              "4       5         8            1  ...  0.638436  1.093227  0.926643\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tc4I8v8p7Xc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e701fc09-997c-4c67-c55e-74f0cd1a587a"
      },
      "source": [
        "df['Score Level'].value_counts().plot(kind='bar')"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4995afcdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMA5_rrpqPYy",
        "colab_type": "text"
      },
      "source": [
        "**Divide variables into independent variables and a dependent variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2IiVDTwlzEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = df.drop(['Score Level'],axis=1), df['Score Level']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY-oyNYiHGYQ",
        "colab_type": "text"
      },
      "source": [
        "**Normalize the data using Standard Scaler**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnJQzfzzqOHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "standard_scaler = StandardScaler()\n",
        "X = standard_scaler.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2NUx08gqgQV",
        "colab_type": "text"
      },
      "source": [
        "**Divide the data into a test and training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3zA-z-dqnDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16b31f9f-48d9-49ed-ec8a-26684acd5ff7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123,stratify=y)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9678, 18) (9678,) (2420, 18) (2420,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRs3lCoTGTqo",
        "colab_type": "text"
      },
      "source": [
        "**Define a deep learning model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7nuPTUP31W7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(1000, activation='relu', input_shape=[X.shape[1]]),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(3)\n",
        "  ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy','mae', 'mse'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX5VbgoEGjYZ",
        "colab_type": "text"
      },
      "source": [
        "**Fit model with Train data with validation split 0.2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok5xj2hP6v38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f320b2be-bf47-42ff-fcea-1f6c722559c2"
      },
      "source": [
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split = 0.2,callbacks=[early_stop, tfdocs.modeling.EpochDots()], epochs=100)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "237/242 [============================>.] - ETA: 0s - loss: 0.8222 - accuracy: 0.6148 - mae: 1.8985 - mse: 5.1108\n",
            "Epoch: 0, accuracy:0.6159,  loss:0.8210,  mae:1.8980,  mse:5.1095,  val_accuracy:0.6653,  val_loss:0.7047,  val_mae:1.8452,  val_mse:4.8620,  \n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.8210 - accuracy: 0.6159 - mae: 1.8980 - mse: 5.1095 - val_loss: 0.7047 - val_accuracy: 0.6653 - val_mae: 1.8452 - val_mse: 4.8620\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7360 - accuracy: 0.6474 - mae: 2.1585 - mse: 6.9829 - val_loss: 0.6686 - val_accuracy: 0.6705 - val_mae: 2.2589 - val_mse: 7.8248\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7192 - accuracy: 0.6567 - mae: 2.3421 - mse: 8.6515 - val_loss: 0.6728 - val_accuracy: 0.6963 - val_mae: 2.3219 - val_mse: 7.9762\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7037 - accuracy: 0.6726 - mae: 2.4583 - mse: 9.9412 - val_loss: 0.6601 - val_accuracy: 0.7014 - val_mae: 2.4153 - val_mse: 9.6316\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6951 - accuracy: 0.6757 - mae: 2.4405 - mse: 10.4277 - val_loss: 0.6613 - val_accuracy: 0.6896 - val_mae: 2.4144 - val_mse: 10.1431\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.6865 - mae: 2.4763 - mse: 11.0123 - val_loss: 0.6692 - val_accuracy: 0.6885 - val_mae: 2.5192 - val_mse: 10.6217\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6883 - accuracy: 0.6815 - mae: 2.4871 - mse: 11.5933 - val_loss: 0.6662 - val_accuracy: 0.6829 - val_mae: 2.5136 - val_mse: 10.7552\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6822 - accuracy: 0.6870 - mae: 2.5656 - mse: 12.7553 - val_loss: 0.6571 - val_accuracy: 0.6885 - val_mae: 2.4699 - val_mse: 11.5530\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6778 - accuracy: 0.6860 - mae: 2.6054 - mse: 13.2681 - val_loss: 0.6608 - val_accuracy: 0.6849 - val_mae: 2.4252 - val_mse: 10.6958\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6716 - accuracy: 0.6904 - mae: 2.5863 - mse: 13.2873 - val_loss: 0.6656 - val_accuracy: 0.6865 - val_mae: 2.5611 - val_mse: 14.0289\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6693 - accuracy: 0.6883 - mae: 2.5994 - mse: 14.8475 - val_loss: 0.6618 - val_accuracy: 0.6911 - val_mae: 2.5006 - val_mse: 12.5289\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6679 - accuracy: 0.6879 - mae: 2.7224 - mse: 16.3951 - val_loss: 0.6672 - val_accuracy: 0.6932 - val_mae: 2.5341 - val_mse: 14.0026\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6667 - accuracy: 0.6909 - mae: 2.6858 - mse: 15.9749 - val_loss: 0.6563 - val_accuracy: 0.6978 - val_mae: 2.7421 - val_mse: 17.2316\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.6927 - mae: 2.7267 - mse: 16.9013 - val_loss: 0.6545 - val_accuracy: 0.7020 - val_mae: 2.5229 - val_mse: 13.6740\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6585 - accuracy: 0.6930 - mae: 2.7058 - mse: 17.7660 - val_loss: 0.6768 - val_accuracy: 0.6937 - val_mae: 2.7110 - val_mse: 18.2808\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6559 - accuracy: 0.6927 - mae: 2.8180 - mse: 20.3325 - val_loss: 0.6687 - val_accuracy: 0.6906 - val_mae: 2.7353 - val_mse: 18.3070\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6528 - accuracy: 0.6922 - mae: 2.8581 - mse: 20.7607 - val_loss: 0.6660 - val_accuracy: 0.6901 - val_mae: 2.6045 - val_mse: 16.0991\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6465 - accuracy: 0.6990 - mae: 2.8272 - mse: 20.8921 - val_loss: 0.6872 - val_accuracy: 0.6736 - val_mae: 2.8256 - val_mse: 20.6539\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6421 - accuracy: 0.6992 - mae: 2.9235 - mse: 22.7251 - val_loss: 0.6705 - val_accuracy: 0.6937 - val_mae: 2.8503 - val_mse: 20.4917\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6358 - accuracy: 0.6984 - mae: 2.9029 - mse: 21.5435 - val_loss: 0.6651 - val_accuracy: 0.6911 - val_mae: 2.9421 - val_mse: 22.7662\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6291 - accuracy: 0.7011 - mae: 3.0491 - mse: 26.0453 - val_loss: 0.6758 - val_accuracy: 0.6880 - val_mae: 2.7386 - val_mse: 20.2321\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6285 - accuracy: 0.7015 - mae: 3.0347 - mse: 26.4344 - val_loss: 0.6923 - val_accuracy: 0.6761 - val_mae: 3.1197 - val_mse: 28.6157\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6224 - accuracy: 0.6989 - mae: 3.1415 - mse: 27.9669 - val_loss: 0.6948 - val_accuracy: 0.6865 - val_mae: 3.0026 - val_mse: 24.7199\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6183 - accuracy: 0.7024 - mae: 3.2059 - mse: 31.0417 - val_loss: 0.7120 - val_accuracy: 0.6834 - val_mae: 3.0251 - val_mse: 24.1471\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6069 - accuracy: 0.7162 - mae: 3.3450 - mse: 33.4153 - val_loss: 0.6986 - val_accuracy: 0.6829 - val_mae: 3.1665 - val_mse: 26.6130\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5991 - accuracy: 0.7182 - mae: 3.3862 - mse: 34.3207 - val_loss: 0.7178 - val_accuracy: 0.6823 - val_mae: 3.3400 - val_mse: 32.4852\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5966 - accuracy: 0.7198 - mae: 3.4242 - mse: 36.6087 - val_loss: 0.7210 - val_accuracy: 0.6803 - val_mae: 3.2802 - val_mse: 31.5554\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5879 - accuracy: 0.7223 - mae: 3.5389 - mse: 39.6528 - val_loss: 0.7458 - val_accuracy: 0.6751 - val_mae: 3.4254 - val_mse: 36.0346\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5833 - accuracy: 0.7191 - mae: 3.7857 - mse: 49.3498 - val_loss: 0.7597 - val_accuracy: 0.6694 - val_mae: 3.7541 - val_mse: 52.1419\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5714 - accuracy: 0.7294 - mae: 3.8341 - mse: 56.4439 - val_loss: 0.7658 - val_accuracy: 0.6637 - val_mae: 3.9698 - val_mse: 57.0056\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5591 - accuracy: 0.7309 - mae: 4.1538 - mse: 62.5491 - val_loss: 0.8155 - val_accuracy: 0.6756 - val_mae: 4.3822 - val_mse: 62.4528\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5535 - accuracy: 0.7344 - mae: 4.2117 - mse: 64.5565 - val_loss: 0.7560 - val_accuracy: 0.6581 - val_mae: 3.7864 - val_mse: 55.4605\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5465 - accuracy: 0.7347 - mae: 4.3634 - mse: 74.1770 - val_loss: 0.8061 - val_accuracy: 0.6524 - val_mae: 4.2016 - val_mse: 60.4517\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5384 - accuracy: 0.7412 - mae: 4.4794 - mse: 76.6339 - val_loss: 0.8124 - val_accuracy: 0.6555 - val_mae: 4.2015 - val_mse: 69.4677\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5189 - accuracy: 0.7506 - mae: 4.6659 - mse: 83.7840 - val_loss: 0.9199 - val_accuracy: 0.6627 - val_mae: 5.0220 - val_mse: 95.1313\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5138 - accuracy: 0.7534 - mae: 4.8129 - mse: 94.7860 - val_loss: 0.8833 - val_accuracy: 0.6524 - val_mae: 4.7928 - val_mse: 84.0790\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5126 - accuracy: 0.7592 - mae: 5.0504 - mse: 107.5493 - val_loss: 0.8723 - val_accuracy: 0.6586 - val_mae: 4.5667 - val_mse: 99.3389\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5014 - accuracy: 0.7591 - mae: 5.1380 - mse: 110.8490 - val_loss: 0.8778 - val_accuracy: 0.6544 - val_mae: 5.0223 - val_mse: 105.8761\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4880 - accuracy: 0.7698 - mae: 5.3400 - mse: 124.1073 - val_loss: 0.9548 - val_accuracy: 0.6555 - val_mae: 4.6794 - val_mse: 86.8789\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4802 - accuracy: 0.7696 - mae: 5.4152 - mse: 132.5519 - val_loss: 0.9369 - val_accuracy: 0.6565 - val_mae: 5.2147 - val_mse: 115.4047\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4806 - accuracy: 0.7703 - mae: 5.6202 - mse: 144.7244 - val_loss: 0.9120 - val_accuracy: 0.6379 - val_mae: 4.8757 - val_mse: 105.5281\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4794 - accuracy: 0.7716 - mae: 5.6550 - mse: 149.2589 - val_loss: 1.0441 - val_accuracy: 0.6570 - val_mae: 5.8108 - val_mse: 150.5597\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4527 - accuracy: 0.7826 - mae: 6.0595 - mse: 172.9520 - val_loss: 1.0100 - val_accuracy: 0.6534 - val_mae: 5.8561 - val_mse: 171.9195\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4585 - accuracy: 0.7846 - mae: 6.0981 - mse: 172.0529 - val_loss: 1.0747 - val_accuracy: 0.6519 - val_mae: 6.2242 - val_mse: 173.2616\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4521 - accuracy: 0.7873 - mae: 6.3686 - mse: 184.8868 - val_loss: 1.0838 - val_accuracy: 0.6296 - val_mae: 6.7679 - val_mse: 398.5557\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4510 - accuracy: 0.7847 - mae: 6.7867 - mse: 370.4332 - val_loss: 1.0573 - val_accuracy: 0.6374 - val_mae: 6.2650 - val_mse: 257.8862\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4297 - accuracy: 0.8043 - mae: 6.9012 - mse: 348.8010 - val_loss: 1.1555 - val_accuracy: 0.6467 - val_mae: 6.4966 - val_mse: 317.3824\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4358 - accuracy: 0.7986 - mae: 6.7265 - mse: 315.2917 - val_loss: 1.1028 - val_accuracy: 0.6482 - val_mae: 6.8420 - val_mse: 333.3428\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4142 - accuracy: 0.8096 - mae: 7.2495 - mse: 354.8433 - val_loss: 1.2294 - val_accuracy: 0.6457 - val_mae: 7.0755 - val_mse: 316.8183\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4117 - accuracy: 0.8127 - mae: 7.3839 - mse: 385.5930 - val_loss: 1.2389 - val_accuracy: 0.6343 - val_mae: 6.9972 - val_mse: 334.0280\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4085 - accuracy: 0.8137 - mae: 7.2814 - mse: 325.5521 - val_loss: 1.3101 - val_accuracy: 0.6534 - val_mae: 7.4641 - val_mse: 332.2929\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3892 - accuracy: 0.8228 - mae: 7.5458 - mse: 362.2922 - val_loss: 1.4692 - val_accuracy: 0.6317 - val_mae: 7.2553 - val_mse: 289.8278\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3851 - accuracy: 0.8267 - mae: 7.7749 - mse: 416.1057 - val_loss: 1.4237 - val_accuracy: 0.6327 - val_mae: 7.2249 - val_mse: 326.4611\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3895 - accuracy: 0.8203 - mae: 7.7870 - mse: 454.8189 - val_loss: 1.4146 - val_accuracy: 0.6343 - val_mae: 8.7406 - val_mse: 521.2628\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3946 - accuracy: 0.8198 - mae: 8.1001 - mse: 419.5915 - val_loss: 1.5088 - val_accuracy: 0.6503 - val_mae: 7.9561 - val_mse: 428.3512\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3658 - accuracy: 0.8365 - mae: 8.2798 - mse: 516.0793 - val_loss: 1.5656 - val_accuracy: 0.6126 - val_mae: 7.8479 - val_mse: 413.5886\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3785 - accuracy: 0.8311 - mae: 8.2588 - mse: 479.0963 - val_loss: 1.3707 - val_accuracy: 0.6245 - val_mae: 7.2085 - val_mse: 348.8439\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3723 - accuracy: 0.8367 - mae: 7.9384 - mse: 426.2408 - val_loss: 1.4980 - val_accuracy: 0.6389 - val_mae: 8.0822 - val_mse: 456.6824\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3536 - accuracy: 0.8446 - mae: 8.4294 - mse: 536.4727 - val_loss: 1.5972 - val_accuracy: 0.6353 - val_mae: 8.1383 - val_mse: 443.8206\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3538 - accuracy: 0.8499 - mae: 8.4600 - mse: 485.8972 - val_loss: 1.6206 - val_accuracy: 0.6245 - val_mae: 7.8886 - val_mse: 500.2829\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3406 - accuracy: 0.8534 - mae: 8.4728 - mse: 575.0023 - val_loss: 1.6279 - val_accuracy: 0.6348 - val_mae: 8.9531 - val_mse: 543.8303\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3500 - accuracy: 0.8484 - mae: 8.8319 - mse: 586.9247 - val_loss: 1.7415 - val_accuracy: 0.6276 - val_mae: 9.3768 - val_mse: 649.7707\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3281 - accuracy: 0.8534 - mae: 8.9352 - mse: 585.1462 - val_loss: 1.7427 - val_accuracy: 0.6157 - val_mae: 8.8992 - val_mse: 567.3216\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3168 - accuracy: 0.8611 - mae: 9.3935 - mse: 693.1869 - val_loss: 1.6725 - val_accuracy: 0.6245 - val_mae: 8.5343 - val_mse: 576.8703\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3095 - accuracy: 0.8704 - mae: 9.5396 - mse: 623.0011 - val_loss: 1.9362 - val_accuracy: 0.6333 - val_mae: 9.1626 - val_mse: 594.3967\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3160 - accuracy: 0.8653 - mae: 9.4137 - mse: 671.3030 - val_loss: 1.7729 - val_accuracy: 0.6142 - val_mae: 8.9155 - val_mse: 576.1294\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3112 - accuracy: 0.8658 - mae: 9.8501 - mse: 671.9359 - val_loss: 1.6565 - val_accuracy: 0.6173 - val_mae: 8.5064 - val_mse: 537.8244\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3026 - accuracy: 0.8681 - mae: 9.5264 - mse: 716.2374 - val_loss: 1.9448 - val_accuracy: 0.6286 - val_mae: 9.2319 - val_mse: 570.9238\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3037 - accuracy: 0.8719 - mae: 9.8594 - mse: 596.5364 - val_loss: 1.7702 - val_accuracy: 0.6281 - val_mae: 9.0990 - val_mse: 599.3694\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2929 - accuracy: 0.8777 - mae: 9.9418 - mse: 685.1492 - val_loss: 1.8856 - val_accuracy: 0.6219 - val_mae: 9.1655 - val_mse: 576.1499\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2875 - accuracy: 0.8799 - mae: 10.1561 - mse: 743.9467 - val_loss: 2.1887 - val_accuracy: 0.6379 - val_mae: 10.7676 - val_mse: 726.0351\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2909 - accuracy: 0.8782 - mae: 9.9323 - mse: 634.6597 - val_loss: 1.8853 - val_accuracy: 0.6209 - val_mae: 9.6987 - val_mse: 614.6558\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2827 - accuracy: 0.8839 - mae: 10.3176 - mse: 662.7108 - val_loss: 2.0552 - val_accuracy: 0.6281 - val_mae: 10.2651 - val_mse: 540.5211\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2865 - accuracy: 0.8813 - mae: 10.4529 - mse: 675.7552 - val_loss: 1.8472 - val_accuracy: 0.6302 - val_mae: 9.8808 - val_mse: 609.4524\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2514 - accuracy: 0.8987 - mae: 10.8361 - mse: 752.7684 - val_loss: 1.9971 - val_accuracy: 0.6235 - val_mae: 10.0793 - val_mse: 618.0093\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2624 - accuracy: 0.8857 - mae: 10.6442 - mse: 686.1913 - val_loss: 2.2065 - val_accuracy: 0.6255 - val_mae: 10.6008 - val_mse: 610.0136\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2776 - accuracy: 0.8848 - mae: 10.4102 - mse: 658.0920 - val_loss: 1.9423 - val_accuracy: 0.6152 - val_mae: 9.6932 - val_mse: 533.9413\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2448 - accuracy: 0.8996 - mae: 10.8758 - mse: 620.5132 - val_loss: 2.2914 - val_accuracy: 0.6260 - val_mae: 10.9642 - val_mse: 687.0902\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2589 - accuracy: 0.8954 - mae: 11.2244 - mse: 715.8557 - val_loss: 2.1005 - val_accuracy: 0.6307 - val_mae: 11.2754 - val_mse: 758.0970\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2506 - accuracy: 0.8983 - mae: 10.8602 - mse: 710.1263 - val_loss: 2.0549 - val_accuracy: 0.5997 - val_mae: 9.9638 - val_mse: 639.1123\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2548 - accuracy: 0.8965 - mae: 10.8158 - mse: 748.6354 - val_loss: 2.1855 - val_accuracy: 0.6178 - val_mae: 10.7420 - val_mse: 829.4630\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2416 - accuracy: 0.8993 - mae: 11.3050 - mse: 766.8752 - val_loss: 2.1937 - val_accuracy: 0.6296 - val_mae: 10.8082 - val_mse: 575.9385\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2128 - accuracy: 0.9172 - mae: 11.6938 - mse: 877.7209 - val_loss: 2.2750 - val_accuracy: 0.6198 - val_mae: 10.8870 - val_mse: 696.4462\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2186 - accuracy: 0.9123 - mae: 11.8380 - mse: 896.4348 - val_loss: 2.5250 - val_accuracy: 0.6235 - val_mae: 11.5091 - val_mse: 750.7566\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2137 - accuracy: 0.9158 - mae: 12.4777 - mse: 1020.2263 - val_loss: 2.3775 - val_accuracy: 0.6281 - val_mae: 11.4436 - val_mse: 913.6870\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2381 - accuracy: 0.9040 - mae: 12.1899 - mse: 1015.1558 - val_loss: 2.4864 - val_accuracy: 0.6147 - val_mae: 11.1017 - val_mse: 955.9774\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2269 - accuracy: 0.9117 - mae: 11.6328 - mse: 898.0652 - val_loss: 2.6066 - val_accuracy: 0.6327 - val_mae: 12.1048 - val_mse: 780.2581\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2416 - accuracy: 0.9053 - mae: 12.0655 - mse: 855.5855 - val_loss: 2.2790 - val_accuracy: 0.6224 - val_mae: 11.2804 - val_mse: 680.4496\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2359 - accuracy: 0.9038 - mae: 11.7321 - mse: 896.7844 - val_loss: 2.2914 - val_accuracy: 0.6049 - val_mae: 10.8077 - val_mse: 733.1805\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.1993 - accuracy: 0.9194 - mae: 12.2143 - mse: 915.9012 - val_loss: 2.4545 - val_accuracy: 0.6193 - val_mae: 11.4440 - val_mse: 754.9242\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2161 - accuracy: 0.9179 - mae: 12.4102 - mse: 914.1747 - val_loss: 2.4285 - val_accuracy: 0.6379 - val_mae: 12.0721 - val_mse: 746.7066\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.1976 - accuracy: 0.9234 - mae: 12.5118 - mse: 1030.7546 - val_loss: 2.4489 - val_accuracy: 0.6193 - val_mae: 11.8467 - val_mse: 870.9713\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2226 - accuracy: 0.9179 - mae: 12.2445 - mse: 886.5197 - val_loss: 2.2225 - val_accuracy: 0.6250 - val_mae: 11.1419 - val_mse: 655.0253\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.1946 - accuracy: 0.9243 - mae: 12.0819 - mse: 821.9753 - val_loss: 2.5577 - val_accuracy: 0.6281 - val_mae: 11.8336 - val_mse: 827.2106\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.1636 - accuracy: 0.9376 - mae: 12.7585 - mse: 863.8431 - val_loss: 2.7974 - val_accuracy: 0.6229 - val_mae: 12.2213 - val_mse: 747.4641\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.1881 - accuracy: 0.9256 - mae: 13.0362 - mse: 921.4686 - val_loss: 2.3750 - val_accuracy: 0.6111 - val_mae: 11.4826 - val_mse: 661.8527\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.1986 - accuracy: 0.9241 - mae: 12.5855 - mse: 919.2396 - val_loss: 2.5701 - val_accuracy: 0.6338 - val_mae: 11.5059 - val_mse: 748.2811\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9247 - mae: 12.3757 - mse: 861.3510 - val_loss: 2.6081 - val_accuracy: 0.6105 - val_mae: 11.3888 - val_mse: 725.7849\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.1799 - accuracy: 0.9313 - mae: 12.7240 - mse: 905.4979 - val_loss: 2.7846 - val_accuracy: 0.6286 - val_mae: 12.1637 - val_mse: 746.9821\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.1824 - accuracy: 0.9323 - mae: 12.6185 - mse: 953.0967 - val_loss: 2.9712 - val_accuracy: 0.6198 - val_mae: 12.8123 - val_mse: 856.9298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYPRUCcpAJKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "b2465e30-265e-424a-b4dc-623df81e682b"
      },
      "source": [
        "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
        "\n",
        "plotter.plot({'Accuracy': history}, metric = \"accuracy\")\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('accuracy')"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LIX2u0zBm8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3e0fc148-f928-43a5-a845-120806e45acb"
      },
      "source": [
        "loss, accuracy ,mae, mse = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "print(\"Testing set loss: {:5.2f} , accuracy: {:5.2f}, mae: {:5.2f}, mse: {:5.2f}  \".format(loss, accuracy, mae, mse))"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76/76 - 0s - loss: 2.9257 - accuracy: 0.6298 - mae: 12.2840 - mse: 644.5778\n",
            "Testing set loss:  2.93 , accuracy:  0.63, mae: 12.28, mse: 644.58  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmPUwtFkBM_t",
        "colab_type": "text"
      },
      "source": [
        "Code Reference \n",
        "\n",
        "\n",
        "1.   https://www.tensorflow.org/tutorials/keras/regression\n",
        "2.   List item\n",
        "\n"
      ]
    }
  ]
}